{
    "meanPayoff -m data/models/virus.prism --precision 0.01 --maxReward 1 --revisitThreshold 6 --errorTolerance 0.1 --pMin 0.1 --maxSuccessors 2 --iterSample 10000 --informationLevel BLACKBOX --updateMethod GREYBOX": [
        {
            "run": 1,
            "bounds": [
                0.0,
                0.008594246812723244
            ],
            "value": 0.004297123406361622,
            "states_explored": 809,
            "time_taken": 166.64
        },
        {
            "run": 2,
            "bounds": [
                0.0,
                0.00807594717603217
            ],
            "value": 0.004037973588016085,
            "states_explored": 809,
            "time_taken": 147.956
        },
        {
            "run": 3,
            "bounds": [
                0.0,
                0.007758063642252514
            ],
            "value": 0.003879031821126257,
            "states_explored": 809,
            "time_taken": 149.691
        },
        {
            "run": 4,
            "bounds": [
                0.0,
                0.009249628652194173
            ],
            "value": 0.0046248143260970865,
            "states_explored": 809,
            "time_taken": 149.935
        },
        {
            "run": 5,
            "bounds": [
                0.0,
                0.008254638423867056
            ],
            "value": 0.004127319211933528,
            "states_explored": 809,
            "time_taken": 138.828
        }
    ],
    "meanPayoff -m data/models/cs_nfail3.prism --precision 0.01 --maxReward 1 --revisitThreshold 6 --errorTolerance 0.1 --pMin 0.1 --maxSuccessors 2 --iterSample 10000 --informationLevel BLACKBOX --updateMethod GREYBOX": [
        {
            "run": 1,
            "bounds": [
                0.33244007220711325,
                0.34224369839433266
            ],
            "value": 0.33734188530072295,
            "states_explored": 183,
            "time_taken": 108.564
        },
        {
            "run": 2,
            "bounds": [
                0.33244007220711236,
                0.33775916153369223
            ],
            "value": 0.3350996168704023,
            "states_explored": 184,
            "time_taken": 80.696
        },
        {
            "run": 3,
            "bounds": [
                0.3324400722071123,
                0.3394706030462979
            ],
            "value": 0.3359553376267051,
            "states_explored": 184,
            "time_taken": 87.7
        },
        {
            "run": 4,
            "bounds": [
                0.33244007220711247,
                0.33802385860552914
            ],
            "value": 0.33523196540632083,
            "states_explored": 184,
            "time_taken": 93.12
        },
        {
            "run": 5,
            "bounds": [
                0.33244007220711314,
                0.33725733263589547
            ],
            "value": 0.33484870242150433,
            "states_explored": 184,
            "time_taken": 85.703
        }
    ],
    "meanPayoff -m data/models/investor.prism --precision 0.01 --maxReward 1 --revisitThreshold 6 --errorTolerance 0.1 --pMin 0.016 --maxSuccessors 8 --iterSample 10000 --informationLevel BLACKBOX --updateMethod GREYBOX": [
        {
            "run": 1,
            "bounds": [
                0.9453492289799766,
                0.9548629389409592
            ],
            "value": 0.9501060839604679,
            "states_explored": 5834,
            "time_taken": 242.127
        },
        {
            "run": 2,
            "bounds": [
                0.9451130763209805,
                0.954638027361595
            ],
            "value": 0.9498755518412878,
            "states_explored": 5861,
            "time_taken": 246.563
        },
        {
            "run": 3,
            "bounds": [
                0.9454045902638062,
                0.9550237361535513
            ],
            "value": 0.9502141632086787,
            "states_explored": 5801,
            "time_taken": 237.793
        },
        {
            "run": 4,
            "bounds": [
                0.9453161732063358,
                0.954840054086209
            ],
            "value": 0.9500781136462724,
            "states_explored": 5863,
            "time_taken": 245.981
        },
        {
            "run": 5,
            "bounds": [
                0.9452373101411939,
                0.9547554332280596
            ],
            "value": 0.9499963716846267,
            "states_explored": 5867,
            "time_taken": 258.976
        }
    ],
    "meanPayoff -m data/models/zeroconf_rewards.prism --precision 0.01 --maxReward 1 --revisitThreshold 6 --errorTolerance 0.1 --pMin 0.0002 --maxSuccessors 6 --iterSample 10000 --const N=40,K=10,reset=false --rewardModule reach --informationLevel BLACKBOX --updateMethod GREYBOX": [
        {
            "run": 1,
            "bounds": [
                0.9901067298925686,
                1.0
            ],
            "value": 0.9950533649462843,
            "states_explored": 339,
            "time_taken": 64.159
        },
        {
            "run": 2,
            "bounds": [
                0.9901085699425426,
                1.0
            ],
            "value": 0.9950542849712714,
            "states_explored": 396,
            "time_taken": 85.685
        },
        {
            "run": 3,
            "bounds": [
                0.9901046682837114,
                1.0
            ],
            "value": 0.9950523341418557,
            "states_explored": 346,
            "time_taken": 64.87
        },
        {
            "run": 4,
            "bounds": [
                0.9900216291820153,
                1.0
            ],
            "value": 0.9950108145910077,
            "states_explored": 407,
            "time_taken": 84.431
        },
        {
            "run": 5,
            "bounds": [
                0.9900199752038412,
                1.0
            ],
            "value": 0.9950099876019206,
            "states_explored": 450,
            "time_taken": 86.272
        }
    ],
    "meanPayoff -m data/models/sensors.prism --precision 0.01 --maxReward 1 --revisitThreshold 6 --errorTolerance 0.1 --pMin 0.05 --maxSuccessors 2 --iterSample 10000 --const K=3 --informationLevel BLACKBOX --updateMethod GREYBOX": [
        {
            "run": 1,
            "bounds": [
                0.3318589086994154,
                0.33529234295761273
            ],
            "value": 0.3335756258285141,
            "states_explored": 189,
            "time_taken": 63.521
        },
        {
            "run": 2,
            "bounds": [
                0.3327269967104237,
                0.3366159260975708
            ],
            "value": 0.3346714614039973,
            "states_explored": 189,
            "time_taken": 63.017
        },
        {
            "run": 3,
            "bounds": [
                0.331809655474892,
                0.33627162521174186
            ],
            "value": 0.33404064034331693,
            "states_explored": 189,
            "time_taken": 23.598
        },
        {
            "run": 4,
            "bounds": [
                0.331830657769192,
                0.33632126945347957
            ],
            "value": 0.3340759636113358,
            "states_explored": 189,
            "time_taken": 31.739
        },
        {
            "run": 5,
            "bounds": [
                0.33217745692565614,
                0.336376813714579
            ],
            "value": 0.3342771353201176,
            "states_explored": 188,
            "time_taken": 68.405
        }
    ],
    "meanPayoff -m data/models/consensus.2.prism --precision 0.01 --maxReward 1 --revisitThreshold 6 --errorTolerance 0.1 --pMin 0.5 --maxSuccessors 2 --iterSample 10000 -c K=2 --rewardModule custom --informationLevel BLACKBOX --updateMethod GREYBOX": [
        {
            "run": 1,
            "bounds": [
                0.10366145347364718,
                0.1136493898892594
            ],
            "value": 0.10865542168145328,
            "states_explored": 272,
            "time_taken": 120.343
        },
        {
            "run": 2,
            "bounds": [
                0.10311795300153258,
                0.11309420635054411
            ],
            "value": 0.10810607967603834,
            "states_explored": 272,
            "time_taken": 126.799
        },
        {
            "run": 3,
            "bounds": [
                0.1033525382655289,
                0.11331997850677412
            ],
            "value": 0.10833625838615152,
            "states_explored": 272,
            "time_taken": 122.303
        },
        {
            "run": 4,
            "bounds": [
                0.1035300779231099,
                0.1135118468104213
            ],
            "value": 0.1085209623667656,
            "states_explored": 272,
            "time_taken": 122.565
        },
        {
            "run": 5,
            "bounds": [
                0.10423102569164952,
                0.11422032582396317
            ],
            "value": 0.10922567575780634,
            "states_explored": 272,
            "time_taken": 114.791
        }
    ],
    "meanPayoff -m data/models/ij.10.prism --precision 0.01 --maxReward 1 --revisitThreshold 6 --errorTolerance 0.1 --pMin 0.5 --maxSuccessors 2 --iterSample 10000 --informationLevel BLACKBOX --updateMethod GREYBOX": [
        {
            "run": 1,
            "bounds": [
                0.9999885825420365,
                1.0
            ],
            "value": 0.9999942912710182,
            "states_explored": 1023,
            "time_taken": 12.105
        },
        {
            "run": 2,
            "bounds": [
                0.9999890709456427,
                1.0
            ],
            "value": 0.9999945354728214,
            "states_explored": 1023,
            "time_taken": 12.122
        },
        {
            "run": 3,
            "bounds": [
                0.9999891657681911,
                1.0
            ],
            "value": 0.9999945828840955,
            "states_explored": 1023,
            "time_taken": 12.203
        },
        {
            "run": 4,
            "bounds": [
                0.9999899141646394,
                1.0
            ],
            "value": 0.9999949570823197,
            "states_explored": 1023,
            "time_taken": 12.014
        },
        {
            "run": 5,
            "bounds": [
                0.9999902441918005,
                1.0
            ],
            "value": 0.9999951220959002,
            "states_explored": 1023,
            "time_taken": 11.856
        }
    ],
    "meanPayoff -m data/models/ij.3.prism --precision 0.01 --maxReward 1 --revisitThreshold 6 --errorTolerance 0.1 --pMin 0.5 --maxSuccessors 2 --iterSample 10000 --informationLevel BLACKBOX --updateMethod GREYBOX": [
        {
            "run": 1,
            "bounds": [
                0.9999774520525345,
                1.0
            ],
            "value": 0.9999887260262672,
            "states_explored": 7,
            "time_taken": 0.338
        },
        {
            "run": 2,
            "bounds": [
                0.9999652824019475,
                1.0
            ],
            "value": 0.9999826412009738,
            "states_explored": 7,
            "time_taken": 0.344
        },
        {
            "run": 3,
            "bounds": [
                0.9999817255089143,
                1.0
            ],
            "value": 0.9999908627544571,
            "states_explored": 7,
            "time_taken": 0.355
        },
        {
            "run": 4,
            "bounds": [
                0.9999806780054882,
                1.0
            ],
            "value": 0.999990339002744,
            "states_explored": 7,
            "time_taken": 0.344
        },
        {
            "run": 5,
            "bounds": [
                0.9999812614335645,
                1.0
            ],
            "value": 0.9999906307167823,
            "states_explored": 7,
            "time_taken": 0.348
        }
    ],
    "meanPayoff -m data/models/pacman.prism --precision 0.01 --maxReward 1 --revisitThreshold 6 --errorTolerance 0.1 --pMin 0.08 --maxSuccessors 6 --iterSample 10000 -c MAXSTEPS=5 --informationLevel BLACKBOX --updateMethod GREYBOX": [
        {
            "run": 1,
            "bounds": [
                0.5480875634726133,
                0.5580847645469765
            ],
            "value": 0.5530861640097949,
            "states_explored": 498,
            "time_taken": 141.202
        },
        {
            "run": 2,
            "bounds": [
                0.547804954349513,
                0.557802730012283
            ],
            "value": 0.5528038421808981,
            "states_explored": 498,
            "time_taken": 136.081
        },
        {
            "run": 3,
            "bounds": [
                0.5473074623759618,
                0.5572782582007978
            ],
            "value": 0.5522928602883799,
            "states_explored": 496,
            "time_taken": 138.228
        },
        {
            "run": 4,
            "bounds": [
                0.5470307974688741,
                0.5570063885175539
            ],
            "value": 0.552018592993214,
            "states_explored": 496,
            "time_taken": 137.7
        },
        {
            "run": 5,
            "bounds": [
                0.547505664348955,
                0.5575047431341437
            ],
            "value": 0.5525052037415493,
            "states_explored": 496,
            "time_taken": 137.91
        }
    ],
    "meanPayoff -m data/models/wlan.0.prism --precision 0.01 --maxReward 1 --revisitThreshold 6 --errorTolerance 0.1 --pMin 0.0625 --maxSuccessors 16 --iterSample 10000 -c COL=0 --rewardModule default --informationLevel BLACKBOX --updateMethod GREYBOX": [
        {
            "run": 1,
            "bounds": [
                1.0,
                1.0
            ],
            "value": 1.0,
            "states_explored": 2944,
            "time_taken": 9.403
        },
        {
            "run": 2,
            "bounds": [
                1.0,
                1.0
            ],
            "value": 1.0,
            "states_explored": 2935,
            "time_taken": 9.505
        },
        {
            "run": 3,
            "bounds": [
                1.0,
                1.0
            ],
            "value": 1.0,
            "states_explored": 2939,
            "time_taken": 9.545
        },
        {
            "run": 4,
            "bounds": [
                1.0,
                1.0
            ],
            "value": 1.0,
            "states_explored": 2932,
            "time_taken": 9.535
        },
        {
            "run": 5,
            "bounds": [
                1.0,
                1.0
            ],
            "value": 1.0,
            "states_explored": 2941,
            "time_taken": 9.276
        }
    ],
    "meanPayoff -m data/models/blackjack.prism --precision 0.01 --maxReward 1.5 --revisitThreshold 6 --errorTolerance 0.1 --pMin 0.076 --maxSuccessors 10 --iterSamples 10000 --informationLevel BLACKBOX --updateMethod GREYBOX": [
        {
            "run": 1,
            "bounds": [
                0.0,
                0.0031315182023146193
            ],
            "value": 0.0023486386517359644,
            "states_explored": 3829,
            "time_taken": 51.706
        },
        {
            "run": 2,
            "bounds": [
                0.0,
                0.0033072661908773063
            ],
            "value": 0.0024804496431579796,
            "states_explored": 3829,
            "time_taken": 46.453
        },
        {
            "run": 3,
            "bounds": [
                0.0,
                0.002670817466906937
            ],
            "value": 0.0020031131001802026,
            "states_explored": 3829,
            "time_taken": 55.787
        },
        {
            "run": 4,
            "bounds": [
                0.0,
                0.003239607208956167
            ],
            "value": 0.002429705406717125,
            "states_explored": 3829,
            "time_taken": 48.846
        },
        {
            "run": 5,
            "bounds": [
                0.0,
                0.006648840617875814
            ],
            "value": 0.00498663046340686,
            "states_explored": 3829,
            "time_taken": 47.721
        }
    ],
    "meanPayoff -m data/models/counter.prism --precision 0.01 --maxReward 10 --revisitThreshold 6 --errorTolerance 0.1 --pMin 0.333 --maxSuccessors 2 --iterSamples 10000 --informationLevel BLACKBOX --updateMethod GREYBOX": [
        {
            "run": 1,
            "bounds": [
                0.4999823878438065,
                0.5000000085953531
            ],
            "value": 4.9999119821957985,
            "states_explored": 8,
            "time_taken": 17.389
        },
        {
            "run": 2,
            "bounds": [
                0.4999779195870417,
                0.500000003507975
            ],
            "value": 4.999889615475084,
            "states_explored": 8,
            "time_taken": 18.384
        },
        {
            "run": 3,
            "bounds": [
                0.49997792213733305,
                0.5000000035540978
            ],
            "value": 4.999889628457154,
            "states_explored": 8,
            "time_taken": 14.095
        },
        {
            "run": 4,
            "bounds": [
                0.0,
                0.0
            ],
            "value": 0.0,
            "states_explored": 8,
            "time_taken": 0.646
        },
        {
            "run": 5,
            "bounds": [
                0.4999881477164337,
                0.5000000012771011
            ],
            "value": 4.999940744967674,
            "states_explored": 8,
            "time_taken": 21.231
        }
    ],
    "meanPayoff -m data/models/recycling.prism --precision 0.01 --maxReward 2 --revisitThreshold 6 --errorTolerance 0.1 --pMin 0.199 --maxSuccessors 2 --iterSamples 10000 --informationLevel BLACKBOX --updateMethod GREYBOX": [
        {
            "run": 1,
            "bounds": [
                0.726535148737308,
                0.727762061429865
            ],
            "value": 1.454297210167173,
            "states_explored": 5,
            "time_taken": 0.436
        },
        {
            "run": 2,
            "bounds": [
                0.7262860221023937,
                0.7274930721694242
            ],
            "value": 1.4537790942718178,
            "states_explored": 5,
            "time_taken": 0.449
        },
        {
            "run": 3,
            "bounds": [
                0.7266971603472712,
                0.7279336177267179
            ],
            "value": 1.454630778073989,
            "states_explored": 5,
            "time_taken": 0.44
        },
        {
            "run": 4,
            "bounds": [
                0.7265485974372058,
                0.7277036171180971
            ],
            "value": 1.4542522145553027,
            "states_explored": 5,
            "time_taken": 0.44
        },
        {
            "run": 5,
            "bounds": [
                0.7262852190450992,
                0.7275249825617802
            ],
            "value": 1.4538102016068795,
            "states_explored": 5,
            "time_taken": 0.445
        }
    ],
    "meanPayoff -m data/models/busyRing4.prism --precision 0.01 --maxReward 1 --revisitThreshold 6 --errorTolerance 0.1 --pMin 0.125 --iterSample 10000 --informationLevel BLACKBOX --updateMethod GREYBOX": [
        {
            "run": 1,
            "bounds": [
                0.9999999999999989,
                1.0
            ],
            "value": 0.9999999999999994,
            "states_explored": 1554,
            "time_taken": 19.313
        },
        {
            "run": 2,
            "bounds": [
                0.999999999999999,
                0.999999999999999
            ],
            "value": 0.999999999999999,
            "states_explored": 1513,
            "time_taken": 12.705
        },
        {
            "run": 3,
            "bounds": [
                0.9999999999999989,
                1.0
            ],
            "value": 0.9999999999999994,
            "states_explored": 1546,
            "time_taken": 11.823
        },
        {
            "run": 4,
            "bounds": [
                0.9999999999999988,
                1.0
            ],
            "value": 0.9999999999999993,
            "states_explored": 1558,
            "time_taken": 24.143
        },
        {
            "run": 5,
            "bounds": [
                0.999999999999999,
                0.999999999999999
            ],
            "value": 0.999999999999999,
            "states_explored": 1537,
            "time_taken": 13.277
        }
    ],
    "meanPayoff -m data/models/busyRingMC4.prism --precision 0.01 --maxReward 1 --revisitThreshold 6 --errorTolerance 0.1 --pMin 0.0625 --iterSample 10000 --informationLevel BLACKBOX --updateMethod GREYBOX": [
        {
            "run": 1,
            "bounds": [
                0.999999999999999,
                0.999999999999999
            ],
            "value": 0.999999999999999,
            "states_explored": 2527,
            "time_taken": 56.191
        },
        {
            "run": 2,
            "bounds": [
                0.999999999999999,
                0.999999999999999
            ],
            "value": 0.999999999999999,
            "states_explored": 2515,
            "time_taken": 49.748
        },
        {
            "run": 3,
            "bounds": [
                0.999999999999999,
                0.999999999999999
            ],
            "value": 0.999999999999999,
            "states_explored": 2512,
            "time_taken": 88.601
        },
        {
            "run": 4,
            "bounds": [
                0.999999999999999,
                0.999999999999999
            ],
            "value": 0.999999999999999,
            "states_explored": 2509,
            "time_taken": 64.367
        },
        {
            "run": 5,
            "bounds": [
                0.999999999999999,
                0.999999999999999
            ],
            "value": 0.999999999999999,
            "states_explored": 2509,
            "time_taken": 76.492
        }
    ]
}